{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InstRecognitionTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An instrument recognition tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief summary of the tool, the datasets used, how features were extracted from each dataset and how they were classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is called IRMAS, and can be downloaded from: https://www.upf.edu/web/mtg/irmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is split on training data, as well as three different testing data groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All audio files are in 16-bit stereo format, sampled at 44.1kHz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instruments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the instruments, their corresponding labels and the number of audio files in training data. There is a total of 11 of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cello,                 `cel`,   388\n",
    "- clarinet,              `cla`,   505\n",
    "- flute,                 `flu`,   451\n",
    "- acoustic guitar,       `gac`,   637\n",
    "- electric guitar,       `gel`,   760\n",
    "- organ,                 `org`,   682\n",
    "- piano,                 `pia`,   721\n",
    "- saxophone,             `sax`,   626\n",
    "- trumpet,               `tru`,   577\n",
    "- violin,                `vio`,   580\n",
    "- human singing voice,   `voi`,   778"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 6705 .wav files\n",
    "- spread over 11 folders\n",
    "- folders represent instruments and are labeled as such\n",
    "- each file name contains an instrument label, a genre label, and in some cases a drums presence label\n",
    "- each audio file is 3 seconds long\n",
    "- audio files are excerpts of different recordings from the past century\n",
    "- audio files vary in quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 testing groups\n",
    "- test group 1 contains 807 .wav files\n",
    "- test group 2 contains 1301 .wav files\n",
    "- test group 3 contains 766 .wav files\n",
    "- file names do not contain instrument labels\n",
    "- audio file lengths vary from around 5 to 20 seconds\n",
    "- audio files are excerpts from existing songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- with each .wav file in the testing data groups, there is an annotated .txt file, with the same name\n",
    "- every annotated .txt file contains either one or two instrument labels corresponding to the instruments used in the .wav file\n",
    "- the annotated files were generated manually\n",
    "- they are used to validate the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brief summary of the feature extraction, cross-validation and classification algorithms used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 _MFCCs_ (_Mel-Frequency Cepstrum Coefficients_) were used as features and were obtained using `librosa` library for python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MFCCs are derived as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Take the _Fourier Transform_ of a signal\n",
    "2. Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows\n",
    "3. Take the logs of the powers at each of the mel frequencies\n",
    "4. Take the _Discrete Cosine Transform_ (_DCT_) of the list of mel log powers, as if it were a signal\n",
    "5. The _MFCCs_ are the amplitudes of the resulting spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In full, three cross-validation methods were used: Leave One Out, K-Fold and Holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is used on training data, and its goal is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does so by splitting training data into subsets, some of which are used for training the model, and the others for validation. There are exhaustive CV methods, which learn and test on all possible ways to divide the original sample into a training and a validation set. There are also non-exhaustive methods, which do not compute all ways of splitting the original sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leave One Out CV is an exhaustive method, and it uses exactly one sample as the validation set, and all the others for training. It then repeats the process until every sample has been selected for validation (and others for training)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold CV is a non-exhaustive method, and it works by randomly partitioning input samples into k equal-sized subsamples. Of the k subsamples, exactly one subsample is selected for validation, and k-1 for training. The process is repeated k times, with each of the k subsamples being used only once as validation data. The results can be averaged to produce a single estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout is also a non-exhaustive method. The input samples are randomly assigned to two sets, d0 and d1, of which d0 is used for training, and d1 for testing. The size of each set is arbitrary, although the training set should be larger than the testing set. It trains the model on d0, and test on d1. There is only a single run, so its results can be misleading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_KNN_ (_K-Nearest Neighbours_) algorithm was used for instrument classification. The `sklearn` library was used, and from it `neighbors` was imported. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input for training consisted of _MFCCs_ and the corresponding classes (instruments), represented by numbers ranging from 1 to 11. The classes were obtained by parsing the file path to each audio file, getting the name of its parent folder. The name of the folder was later converted to a number, ranging from 1 to 11. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input for testing consisted of _MFCCs_ only, and it was used for prediction. The output was the predicted class, represented by a number, ranging from 1 to 11."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within testing, validation was also done, using validation data, described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy was calculated and represented by a percentage of accurate guesses within the testing group (and later for all testing groups). An accurate guess meant that the prediction of an element's class was the same as the class (or one of the two) provided in the validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K was set to 97, as it was a square root of the number of elements within the dataset. It is also a prime, uneven number, which is also recommended. It also produced the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that for every element within the input test data, 97 nearest neighbours were taken into account when determining the class it belongs to. The output class is determined by the plurality vote; that is, the most common class out of the 97 neighbours is the output class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm was tested for K = {5, 11, 31, 97}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For K = 5, overall accuracy was around 31% for the entire testing set.\n",
    "- For K = 11, overall accuracy was around 34% for the entire testing set.\n",
    "- For K = 31, overall accuracy was around 38% for the entire testing set.\n",
    "- For K = 97, overall accuracy was around 40% for the entire testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy improved with the increase of K, however there was only a slight increase of accuracy that resulted from an increase of K. That was especially noticeable when K was increased from 31 to 97. Increasing K did not negatively affect performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest uses decision trees. The trees consist of nodes, and each node corresponds to an input variable, and leafs, which correspond to classes. Random Forest works by constructing multiple decision trees at training time and outputting the class that is the mode of the classes of the individual trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same dataset was used in the same way for training and testing the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For accuracy, precision, recall and F1 score were used on both classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation reported higher accuracy for RFC, in comparison to KNN, by around 10-30%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Random Forest Classifier did not increase the overall precision on testing data of the algorithm in comparison to K-Nearest Neighbours. It is around 46% for both the KNN and RFC. Recall and F1 score, however, decreased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that the feature selection process could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an accuracy of around 46% is very small, a higher accuracy might be achieved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That can be done in the following ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- increasing the number of features\n",
    "- making the features more unique, perhaps by extracting features differently\n",
    "- limiting the dataset to only a few instruments\n",
    "- using different ML algorithms (such as Bagging)\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions and prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `Anaconda` 5.2.0 for Python 3.6 (py36_3)\n",
    "- `conda` 4.6.3 (py36_0)\n",
    "- `Jupyter notebook` 5.5.0\n",
    "- `numpy` 1.14.3\n",
    "- `scikit-learn` 0.19.1\n",
    "- `glob2` 0.6\n",
    "- `librosa` 0.6.3 from `conda-forge`\n",
    "- `IRMAS dataset` from https://www.upf.edu/web/mtg/irmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, it is required that the extracted IRMAS datasets are placed in the following folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- D:\\College\\Soft Computing\\Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder structure of Data folder should then look like:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- \\ IRMAS-TestingData-Part1 \\ Part1 \\ {.wav & .txt files}\n",
    "- \\ IRMAS-TestingData-Part2 \\ IRTestingData-Part2 \\ {.wav & .txt files}\n",
    "- \\ IRMAS-TestingData-Part3 \\ Part3 \\ {.wav & .txt files}\n",
    "- \\ IRMAS-TrainingData \\ {instrument label} \\ {.wav files}\n",
    "- \\ DEFENSE \\ {.wav & .txt files}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone the project repository.\n",
    "2. Open the `IRT.ipynb` file in a `Jupyter Notebook`.\n",
    "3. From the toolbar, click on `Cell`, then on `Run All`.\n",
    "4. Enjoy the awesomeness that is this project.\n",
    "5. Grade generously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import importlib\n",
    "import read\n",
    "import classi\n",
    "import randomforest as rf\n",
    "import crossvalidation as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAINING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data reading, feature extraction, time spent and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TRAINING DATA ---\n",
      "Feature extraction time: 944.4008223000001 seconds\n",
      "Data size: 6705 audio files\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TRAINING DATA ---\")\n",
    "time_start = time.perf_counter()\n",
    "data = read.fext()\n",
    "elapsed_time = time.perf_counter() - time_start\n",
    "print(\"Feature extraction time:\", elapsed_time, \"seconds\")\n",
    "print(\"Data size:\", len(data), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fitting the data using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = classi.train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fitting the data using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = rf.train(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING ON ONE SAMPLE:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sample reading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataone = read.fextonetest()\n",
    "#print(dataone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction and validation (using an annotated text file that contains the names of either one or two instruments that are present in the audio file of the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct! 5 == 5\n"
     ]
    }
   ],
   "source": [
    "predicted = classi.testone(dataone, knn)\n",
    "if (dataone[3] == predicted[0]):\n",
    "    print(\"Correct!\", dataone[3], \"==\", predicted[0])\n",
    "elif(dataone[2] == predicted[0]):\n",
    "    print(\"Correct!\", dataone[2], \"==\", predicted[0])\n",
    "else:\n",
    "    print(\"Incorrect!\", dataone[3], \"!=\", predicted[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING (DATA PART 1):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data reading, feature extraction, time spent and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TESTING DATA PART 1 ---\n",
      "Feature extraction time: 459.9897995 seconds\n",
      "Data size: 807 audio files\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TESTING DATA PART 1 ---\")\n",
    "time_start = time.perf_counter()\n",
    "data1 = read.fexttest1()\n",
    "elapsed_time = time.perf_counter() - time_start\n",
    "print(\"Feature extraction time:\", elapsed_time, \"seconds\")\n",
    "print(\"Data size:\", len(data1), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on input data, including validation and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc1 = classi.testandverify(data1, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 38.166047087980175 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc1, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING (DATA PART 2):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data reading, feature extraction, time spent and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TESTING DATA PART 2 ---\n",
      "Feature extraction time: 691.2876760999998 seconds\n",
      "Data size: 1301 audio files\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TESTING DATA PART 2 ---\")\n",
    "time_start = time.perf_counter()\n",
    "data2 = read.fexttest2()\n",
    "elapsed_time = time.perf_counter() - time_start\n",
    "print(\"Feature extraction time:\", elapsed_time, \"seconds\")\n",
    "print(\"Data size:\", len(data2), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on input data, including validation and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2 = classi.testandverify(data2, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 45.04227517294389 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc2, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING (DATA PART 3):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data reading, feature extraction, time spent and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TESTING DATA PART 3 ---\n",
      "Feature extraction time: 432.1010712999996 seconds\n",
      "Data size: 766 audio files\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TESTING DATA PART 3 ---\")\n",
    "time_start = time.perf_counter()\n",
    "data3 = read.fexttest3()\n",
    "elapsed_time = time.perf_counter() - time_start\n",
    "print(\"Feature extraction time:\", elapsed_time, \"seconds\")\n",
    "print(\"Data size:\", len(data3), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on input data, including validation and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3 = classi.testandverify(data3, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 36.0313315926893 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc3, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Average accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy: 39.74655128453779 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy:\", (acc1 + acc2 + acc3)/3, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TESTING (CUSTOM DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- data reading, feature extraction, time spent and sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TESTING CUSTOM DATASET ---\n",
      "Feature extraction time: 16.964201700000103 seconds\n",
      "Data size: 30 audio files\n"
     ]
    }
   ],
   "source": [
    "print(\"--- TESTING CUSTOM DATASET ---\")\n",
    "time_start = time.perf_counter()\n",
    "data4 = read.fextcustom()\n",
    "elapsed_time = time.perf_counter() - time_start\n",
    "print(\"Feature extraction time:\", elapsed_time, \"seconds\")\n",
    "print(\"Data size:\", len(data4), \"audio files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prediction on input data, including validation and accuracy calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc4 = classi.testandverify(data4, knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 40.0 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", acc4, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata = []\n",
    "alldata.extend(data1)\n",
    "alldata.extend(data2)\n",
    "alldata.extend(data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave One Out mean accuracy: 37.53914988814317 %\n",
      "K-Fold mean accuracy: 36.689458816202155 %\n",
      "Holdout mean accuracy: 33.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "cv.leave_one_out([i[1] for i in data], [i[2] for i in data], knn)\n",
    "cv.k_fold([i[1] for i in data], [i[2] for i in data], knn)\n",
    "cv.holdout([i[1] for i in data], [i[2] for i in data], knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave One Out mean accuracy: 50.246085011185684 %\n",
      "K-Fold mean accuracy: 47.72549324910471 %\n",
      "Holdout mean accuracy: 66.66666666666666 %\n"
     ]
    }
   ],
   "source": [
    "cv.leave_one_out([i[1] for i in data], [i[2] for i in data], rfc)\n",
    "cv.k_fold([i[1] for i in data], [i[2] for i in data], rfc)\n",
    "cv.holdout([i[1] for i in data], [i[2] for i in data], rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions, confusion matrices and classification reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnpred = classi.test(alldata, knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(alldata)):\n",
    "    if knnpred[i] == alldata[i][3]:\n",
    "        a = alldata[i][2]\n",
    "        alldata[i][2] = knnpred[i]\n",
    "        alldata[i][3] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5   4   1  30   2   9   6   5   0   7  10]\n",
      " [ 16   5   0   9   2   1   9  12   3   2   0]\n",
      " [  2   5   0   7  12  22  47   3   1   5  30]\n",
      " [  7   3   4 135  21  56  58  18   2   8  82]\n",
      " [ 10   4   0  56 305  65  24  17  17   6 178]\n",
      " [  2   2   0  12  19  57  16   4   2  14  29]\n",
      " [ 19  14   3 123  32 115 220  16   3  11 169]\n",
      " [  2   0   0   3   0   2   3  18   1   0   1]\n",
      " [  0   0   0   0   4   1   0   6   1   2   0]\n",
      " [ 23   1   3   6   0   0   3   0   0  34   0]\n",
      " [  8  10   3  23  22  28  11  27   1   7 390]]\n"
     ]
    }
   ],
   "source": [
    "rf.print_confusion_matrix([i[2] for i in alldata], knnpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.05      0.06      0.06        79\n",
      "          2       0.10      0.08      0.09        59\n",
      "          3       0.00      0.00      0.00       134\n",
      "          4       0.33      0.34      0.34       394\n",
      "          5       0.73      0.45      0.55       682\n",
      "          6       0.16      0.36      0.22       157\n",
      "          7       0.55      0.30      0.39       725\n",
      "          8       0.14      0.60      0.23        30\n",
      "          9       0.03      0.07      0.04        14\n",
      "         10       0.35      0.49      0.41        70\n",
      "         11       0.44      0.74      0.55       530\n",
      "\n",
      "avg / total       0.46      0.41      0.41      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.print_classification_report([i[2] for i in alldata], knnpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rf.test(alldata, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(alldata)):\n",
    "    if prediction[i] == alldata[i][3]:\n",
    "        a = alldata[i][2]\n",
    "        alldata[i][2] = prediction[i]\n",
    "        alldata[i][3] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   5   4  10   6   5   2   9   1   9   1]\n",
      " [  5   8   4   8   2   1  12   7   5   2   2]\n",
      " [  4  15  14  10   8  14  26  17   4   2   9]\n",
      " [ 18  16  18 132  39  38  37  45   3   9  37]\n",
      " [ 40  18  17  48 285  69  18  30  23  20  91]\n",
      " [  9   5  16  18  24  41  12   7   9  14   8]\n",
      " [ 41  26  35  76  48  70 246  50  23  17  68]\n",
      " [  3   6   4   2   6   7   2  20   5   2   7]\n",
      " [  1   1   0   1   1   1   2   1   4   5   2]\n",
      " [  9   5   3   3   1   0   7   6   3  38   1]\n",
      " [ 20  17  23  34  73  72  38  45   9  17 200]]\n"
     ]
    }
   ],
   "source": [
    "rf.print_confusion_matrix([i[2] for i in alldata], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.13      0.30      0.18        74\n",
      "          2       0.07      0.14      0.09        56\n",
      "          3       0.10      0.11      0.11       123\n",
      "          4       0.39      0.34      0.36       392\n",
      "          5       0.58      0.43      0.49       659\n",
      "          6       0.13      0.25      0.17       163\n",
      "          7       0.61      0.35      0.45       700\n",
      "          8       0.08      0.31      0.13        64\n",
      "          9       0.04      0.21      0.07        19\n",
      "         10       0.28      0.50      0.36        76\n",
      "         11       0.47      0.36      0.41       548\n",
      "\n",
      "avg / total       0.45      0.35      0.38      2874\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf.print_classification_report([i[2] for i in alldata], prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reload .py files (avoids the need to restart the kernel every time the files are changed)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "importlib.reload(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'classi' from 'D:\\\\College\\\\Soft Computing\\\\instrecognition-tool\\\\classi.py'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(classi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'randomforest' from 'D:\\\\College\\\\Soft Computing\\\\instrecognition-tool\\\\randomforest.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'crossvalidation' from 'D:\\\\College\\\\Soft Computing\\\\instrecognition-tool\\\\crossvalidation.py'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THE END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
